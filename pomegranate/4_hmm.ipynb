{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "642be480",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn; seaborn.set_style('whitegrid')\n",
    "import numpy as np\n",
    "\n",
    "from pomegranate import *\n",
    "\n",
    "np.random.seed(0)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5f1d396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f962007e",
   "metadata": {},
   "source": [
    "## CG rich region identification example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb4a839",
   "metadata": {},
   "source": [
    "Lets take the simplified example of CG island detection on a sequence of DNA. DNA is made up of the four canonical nucleotides, abbreviated 'A', 'C', 'G', and 'T'. We can say that regions of the genome that are enriched for nucleotides 'C' and 'G' are 'CG islands', which is a simplification of the real biological concept but sufficient for our example. The issue with identifying these regions is that they are not exclusively made up of the nucleotides 'C' and 'G', but have some 'A's and 'T's scatted amongst them. A simple model that looked for long stretches of C's and G's would not perform well, because it would miss most of the real regions.\n",
    "\n",
    "We can start off by building the model. Because HMMs involve the transition matrix, which is often represented using a graph over the hidden states, building them requires a few more steps that a simple distribution or the mixture model. Our simple model will be composed of two distributions. One distribution wil be a uniform distribution across all four characters and one will have a preference for the nucleotides C and G, while still allowing the nucleotides A and T to be present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a39aa877",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = DiscreteDistribution({'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25})\n",
    "d2 = DiscreteDistribution({'A': 0.10, 'C': 0.40, 'G': 0.40, 'T': 0.10}) # << C i G występują tutaj częściej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8707ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiujemy dwa stany\n",
    "s1 = State(d1, name='background')\n",
    "s2 = State(d2, name='CG island')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87a215d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzymy model HMM\n",
    "model = HiddenMarkovModel()\n",
    "model.add_states(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5313331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dodajemy prawdopodbieństwa przejścia ze stanu do stanu\n",
    "model.add_transition(model.start, s1, 0.5)\n",
    "model.add_transition(model.start, s2, 0.5)\n",
    "model.add_transition(s1, s1, 0.9)\n",
    "model.add_transition(s1, s2, 0.1)\n",
    "model.add_transition(s2, s1, 0.1)\n",
    "model.add_transition(s2, s2, 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332a2a66",
   "metadata": {},
   "source": [
    "Now, finally, we need to bake the model in order to finalize the internal structure. Bake must be called when the model has been fully specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6a1930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.bake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5171f695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence: CGACTACTGACTACTCGCCGACGCGACTGCCGTCTATACTGCGCATACGGC\n",
      "hmm pred: 111111111111111000000000000000011111111111111110000\n"
     ]
    }
   ],
   "source": [
    "# Uwaga! Indeksy nie odziweciedlają kolejności dodawania stanów\n",
    "seq = numpy.array(list('CGACTACTGACTACTCGCCGACGCGACTGCCGTCTATACTGCGCATACGGC'))\n",
    "\n",
    "hmm_predictions = model.predict(seq)\n",
    "\n",
    "print(\"sequence: {}\".format(''.join(seq)))\n",
    "print(\"hmm pred: {}\".format(''.join(map( str, hmm_predictions))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790b5b66",
   "metadata": {},
   "source": [
    "> The predicted integers don't correspond to the order in which states were added to the model, but rather, the order that they exist in the model after a topological sort. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a0731b",
   "metadata": {},
   "source": [
    "Let's say, though, that we want to get rid of that CG island prediction at the end because we don't believe that real islands can occur at the end of the sequence. We can take care of this by adding in an explicit end state that only the non-island hidden state can get to. We enforce that the model has to end in the end state, and if only the non-island state gets there, the sequence of hidden states must end in the non-island state. Here's how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fef3e572",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HiddenMarkovModel()\n",
    "model.add_states(s1, s2)\n",
    "model.add_transition(model.start, s1, 0.5)\n",
    "model.add_transition(model.start, s2, 0.5)\n",
    "model.add_transition(s1, s1, 0.89 )\n",
    "model.add_transition(s1, s2, 0.10 )\n",
    "model.add_transition(s1, model.end, 0.01)\n",
    "model.add_transition(s2, s1, 0.1)\n",
    "model.add_transition(s2, s2, 0.9)\n",
    "model.bake()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85df60b3",
   "metadata": {},
   "source": [
    "Note that all we did was add a transition from s1 to model.end with some low probability. This probability doesn't have to be high if there's only a single transition there, because there's no other possible way of getting to the end state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "816c1f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence: CGACTACTGACTACTCGCCGACGCGACTGCCGTCTATACTGCGCATACGGC\n",
      "hmm pred: 111111111111111000000000000000011111111111111111111\n"
     ]
    }
   ],
   "source": [
    "seq = numpy.array(list('CGACTACTGACTACTCGCCGACGCGACTGCCGTCTATACTGCGCATACGGC'))\n",
    "\n",
    "hmm_predictions = model.predict(seq)\n",
    "\n",
    "print(\"sequence: {}\".format(''.join(seq)))\n",
    "print(\"hmm pred: {}\".format(''.join(map( str, hmm_predictions))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98139862",
   "metadata": {},
   "source": [
    "In the same way that mixtures could provide probabilistic estimates of class assignments rather than only hard labels, hidden Markov models can do the same. These estimates are the posterior probabilities of belonging to each of the hidden states given the observation, but also given the rest of the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84428815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.19841088 0.80158912]\n",
      " [0.32919701 0.67080299]\n",
      " [0.38366073 0.61633927]\n",
      " [0.58044619 0.41955381]\n",
      " [0.69075524 0.30924476]\n",
      " [0.74653183 0.25346817]\n",
      " [0.76392808 0.23607192]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict_proba(seq)[12:19])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef429fb",
   "metadata": {},
   "source": [
    "Oprócz wyliczenia powyższych prawdopodobieństw (posterior probability), możemy również sprawdzić przewidywaną liczbę przejść między stanami ukrytymi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cb37204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15.78100555  2.89559314  0.          0.        ]\n",
      " [ 2.41288774 28.91051356  0.          1.        ]\n",
      " [ 0.4827054   0.5172946   0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "trans, ems = model.forward_backward(seq)\n",
    "print(trans)\n",
    "# ems = emission (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8f2369d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{\n",
       "     \"class\" : \"State\",\n",
       "     \"distribution\" : {\n",
       "         \"class\" : \"Distribution\",\n",
       "         \"dtype\" : \"str\",\n",
       "         \"name\" : \"DiscreteDistribution\",\n",
       "         \"parameters\" : [\n",
       "             {\n",
       "                 \"A\" : 0.1,\n",
       "                 \"C\" : 0.4,\n",
       "                 \"G\" : 0.4,\n",
       "                 \"T\" : 0.1\n",
       "             }\n",
       "         ],\n",
       "         \"frozen\" : false\n",
       "     },\n",
       "     \"name\" : \"CG island\",\n",
       "     \"weight\" : 1.0\n",
       " },\n",
       " {\n",
       "     \"class\" : \"State\",\n",
       "     \"distribution\" : {\n",
       "         \"class\" : \"Distribution\",\n",
       "         \"dtype\" : \"str\",\n",
       "         \"name\" : \"DiscreteDistribution\",\n",
       "         \"parameters\" : [\n",
       "             {\n",
       "                 \"A\" : 0.25,\n",
       "                 \"C\" : 0.25,\n",
       "                 \"G\" : 0.25,\n",
       "                 \"T\" : 0.25\n",
       "             }\n",
       "         ],\n",
       "         \"frozen\" : false\n",
       "     },\n",
       "     \"name\" : \"background\",\n",
       "     \"weight\" : 1.0\n",
       " },\n",
       " {\n",
       "     \"class\" : \"State\",\n",
       "     \"distribution\" : null,\n",
       "     \"name\" : \"None-start\",\n",
       "     \"weight\" : 1.0\n",
       " },\n",
       " {\n",
       "     \"class\" : \"State\",\n",
       "     \"distribution\" : null,\n",
       "     \"name\" : \"None-end\",\n",
       "     \"weight\" : 1.0\n",
       " }]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kolejność stanów - wiersze macierzy powyżej:\n",
    "# * CG island\n",
    "# * background\n",
    "# * start\n",
    "# * end\n",
    "# \n",
    "# Ze stanu końowego nie przejdziemy już nigdzie, \n",
    "# Nieco częściej przechodzimy ze stanu CG do stanu background, najczęciej pozostajemy w obrębie tego samego stanu.\n",
    "# Nie przejdziemy z CG do stanu końcowego, więc nie musimy go teoretycznie nawet używać\n",
    "model.states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a984e1",
   "metadata": {},
   "source": [
    "This is the transition table, which has the **soft count** of the number of transitions across an edge in the model given a single sequence. It is a square matrix of size equal to the number of states (including start and end state), with number of transitions from (row_id) to (column_id). This is exemplified by the 1.0 in the first row, indicating that there is one transition from background state to the end state, as that's the only way to reach the end state. However, the third (or fourth, depending on ordering) row is the transitions from the start state, and it only slightly favors the background state. These counts are not normalized to the length of the input sequence, but can easily be done so by dividing by row sums, column sums, or entire table sums, depending on your application.\n",
    "\n",
    "A possible reason not to normalize is to run several sequences through and add up their tables, because normalizing in the end and extracting some domain knowledge. It is extremely useful in practice. For example, we can see that there is an expectation of ~2.9 transitions from CG island to background, and ~2.4 from background to CG island. This could be used to infer that there are ~2-3 edges, which makes sense if you consider that the start and end of the sequence seem like they might be part of the CG island states except for the strict transition probabilities used (look at the first few rows of the emission table above.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898ff378",
   "metadata": {},
   "source": [
    "## Sequence Alignment Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf7c7df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HiddenMarkovModel( \"Global Alignment\")\n",
    "\n",
    "# Define the distribution for insertions\n",
    "i_d = DiscreteDistribution( { 'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25 } )\n",
    "\n",
    "# Create the insert states\n",
    "# Prawdopodpdobieństwa mutacji są równe\n",
    "i0 = State( i_d, name=\"I0\" )\n",
    "i1 = State( i_d, name=\"I1\" )\n",
    "i2 = State( i_d, name=\"I2\" )\n",
    "i3 = State( i_d, name=\"I3\" )\n",
    "\n",
    "# Create the match states\n",
    "# Stan produkuje jakieś wyjście z określonym prawdopodobieństwem\n",
    "m1 = State( DiscreteDistribution({ \"A\": 0.95, 'C': 0.01, 'G': 0.01, 'T': 0.02 }) , name=\"M1\" )\n",
    "m2 = State( DiscreteDistribution({ \"A\": 0.003, 'C': 0.99, 'G': 0.003, 'T': 0.004 }) , name=\"M2\" )\n",
    "m3 = State( DiscreteDistribution({ \"A\": 0.01, 'C': 0.01, 'G': 0.01, 'T': 0.97 }) , name=\"M3\" )\n",
    "\n",
    "# Create the delete states\n",
    "# Stan delete nie produkuje żadnego wyjścia\n",
    "d1 = State( None, name=\"D1\" )\n",
    "d2 = State( None, name=\"D2\" )\n",
    "d3 = State( None, name=\"D3\" )\n",
    "\n",
    "# Add all the states to the model\n",
    "model.add_states( [i0, i1, i2, i3, m1, m2, m3, d1, d2, d3 ] )\n",
    "\n",
    "# Create transitions from match states\n",
    "model.add_transition( model.start, m1, 0.9 )\n",
    "model.add_transition( model.start, i0, 0.1 )\n",
    "model.add_transition( m1, m2, 0.9 )\n",
    "model.add_transition( m1, i1, 0.05 )\n",
    "model.add_transition( m1, d2, 0.05 )\n",
    "model.add_transition( m2, m3, 0.9 )\n",
    "model.add_transition( m2, i2, 0.05 )\n",
    "model.add_transition( m2, d3, 0.05 )\n",
    "model.add_transition( m3, model.end, 0.9 )\n",
    "model.add_transition( m3, i3, 0.1 )\n",
    "\n",
    "# Create transitions from insert states\n",
    "model.add_transition( i0, i0, 0.70 )\n",
    "model.add_transition( i0, d1, 0.15 )\n",
    "model.add_transition( i0, m1, 0.15 )\n",
    "\n",
    "model.add_transition( i1, i1, 0.70 )\n",
    "model.add_transition( i1, d2, 0.15 )\n",
    "model.add_transition( i1, m2, 0.15 )\n",
    "\n",
    "model.add_transition( i2, i2, 0.70 )\n",
    "model.add_transition( i2, d3, 0.15 )\n",
    "model.add_transition( i2, m3, 0.15 )\n",
    "\n",
    "model.add_transition( i3, i3, 0.85 )\n",
    "model.add_transition( i3, model.end, 0.15 )\n",
    "\n",
    "# Create transitions from delete states\n",
    "model.add_transition( d1, d2, 0.15 )\n",
    "model.add_transition( d1, i1, 0.15 )\n",
    "model.add_transition( d1, m2, 0.70 ) \n",
    "\n",
    "model.add_transition( d2, d3, 0.15 )\n",
    "model.add_transition( d2, i2, 0.15 )\n",
    "model.add_transition( d2, m3, 0.70 )\n",
    "\n",
    "model.add_transition( d3, i3, 0.30 )\n",
    "model.add_transition( d3, model.end, 0.70 )\n",
    "\n",
    "# Call bake to finalize the structure of the model.\n",
    "model.bake()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f653737",
   "metadata": {},
   "source": [
    "Now lets try to align some sequences to it and see what happens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24e4c720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence: 'ACT'  -- Log Probability: -0.5132449003570658 -- Path: M1 M2 M3\n",
      "Sequence: 'GGC'  -- Log Probability: -11.048101241343396 -- Path: I0 I0 D1 M2 D3\n",
      "Sequence: 'GAT'  -- Log Probability: -9.125519674022627 -- Path: I0 M1 D2 M3\n",
      "Sequence: 'ACC'  -- Log Probability: -5.0879558788604475 -- Path: M1 M2 M3\n"
     ]
    }
   ],
   "source": [
    "for sequence in map( list, ('ACT', 'GGC', 'GAT', 'ACC') ):\n",
    "    logp, path = model.viterbi( sequence )\n",
    "    print(\"Sequence: '{}'  -- Log Probability: {} -- Path: {}\".format(\n",
    "        ''.join( sequence ), logp, \" \".join( state.name for idx, state in path[1:-1] ) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6c4bf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence: 'A'  -- Log Probability: -5.406181012423981 -- Path: M1 D2 D3\n",
      "Sequence: 'GA'  -- Log Probability: -10.88681993576597 -- Path: I0 M1 D2 D3\n",
      "Sequence: 'AC'  -- Log Probability: -3.6244718790494277 -- Path: M1 M2 D3\n",
      "Sequence: 'AT'  -- Log Probability: -3.644880750680635 -- Path: M1 D2 M3\n",
      "Sequence: 'ATCC'  -- Log Probability: -10.674332964640293 -- Path: M1 D2 M3 I3 I3\n",
      "Sequence: 'ACGTG'  -- Log Probability: -10.393824835172445 -- Path: M1 M2 I2 I2 I2 D3\n",
      "Sequence: 'ATTT'  -- Log Probability: -8.67126440174503 -- Path: M1 I1 I1 D2 M3\n",
      "Sequence: 'TACCCTC'  -- Log Probability: -16.903451796110275 -- Path: I0 I0 I0 I0 D1 M2 M3 I3\n",
      "Sequence: 'TGTCAACACT'  -- Log Probability: -16.451699654050792 -- Path: I0 I0 I0 I0 I0 I0 I0 M1 M2 M3\n"
     ]
    }
   ],
   "source": [
    "for sequence in map( list, ('A', 'GA', 'AC', 'AT', 'ATCC', 'ACGTG', 'ATTT', 'TACCCTC', 'TGTCAACACT') ):\n",
    "    logp, path = model.viterbi( sequence )\n",
    "    print(\"Sequence: '{}'  -- Log Probability: {} -- Path: {}\".format(\n",
    "        ''.join( sequence ), logp, \" \".join( state.name for idx, state in path[1:-1] ) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d34c030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence: A, Log Probability: -5.406181012423981\n",
      "ACT\n",
      "A--\n",
      "\n",
      "Sequence: GA, Log Probability: -10.88681993576597\n",
      "-ACT\n",
      "GA--\n",
      "\n",
      "Sequence: AC, Log Probability: -3.6244718790494277\n",
      "ACT\n",
      "AC-\n",
      "\n",
      "Sequence: AT, Log Probability: -3.644880750680635\n",
      "ACT\n",
      "A-T\n",
      "\n",
      "Sequence: ATCC, Log Probability: -10.674332964640293\n",
      "ACT--\n",
      "A-TCC\n",
      "\n",
      "Sequence: ACGTG, Log Probability: -10.393824835172445\n",
      "AC---T\n",
      "ACGTG-\n",
      "\n",
      "Sequence: ATTT, Log Probability: -8.67126440174503\n",
      "A--CT\n",
      "ATT-T\n",
      "\n",
      "Sequence: TACCCTC, Log Probability: -16.903451796110275\n",
      "----ACT-\n",
      "TACC-CTC\n",
      "\n",
      "Sequence: TGTCAACACT, Log Probability: -16.451699654050792\n",
      "-------ACT\n",
      "TGTCAACACT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def path_to_alignment( x, y, path ):\n",
    "    \"\"\"\n",
    "    This function will take in two sequences, and the ML path which is their alignment,\n",
    "    and insert dashes appropriately to make them appear aligned. This consists only of\n",
    "    adding a dash to the model sequence for every insert in the path appropriately, and\n",
    "    a dash in the observed sequence for every delete in the path appropriately.\n",
    "    \"\"\"\n",
    "    \n",
    "    for i, (index, state) in enumerate( path[1:-1] ):\n",
    "        name = state.name\n",
    "        \n",
    "        if name.startswith( 'D' ):\n",
    "            y = y[:i] + '-' + y[i:]\n",
    "        elif name.startswith( 'I' ):\n",
    "            x = x[:i] + '-' + x[i:]\n",
    "\n",
    "    return x, y\n",
    "\n",
    "for sequence in map( list, ('A', 'GA', 'AC', 'AT', 'ATCC', 'ACGTG', 'ATTT', 'TACCCTC', 'TGTCAACACT') ):\n",
    "    logp, path = model.viterbi( sequence )\n",
    "    x, y = path_to_alignment( 'ACT', ''.join(sequence), path )\n",
    "    \n",
    "    print(\"Sequence: {}, Log Probability: {}\".format( ''.join(sequence), logp ))\n",
    "    print(\"{}\\n{}\".format( x, y ))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87e1b74",
   "metadata": {},
   "source": [
    "## Training Hidden Markov Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7dd0bf",
   "metadata": {},
   "source": [
    "There are two main algorithms for training hidden Markov models-- **Baum Welch** (structured version of Expectation Maximization), and **Viterbi** training. Since we don't start off with labels on the data, these are both **unsupervised training algorithms**. In order to assign labels, Baum Welch uses EM to assign soft labels (weights in this case) to each point belonging to each state, and then using weighted MLE estimates to update the distributions. Viterbi assigns hard labels to each observation using the Viterbi algorithm, and then updates the distributions based on these hard labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbd6f6e",
   "metadata": {},
   "source": [
    "* **[Baum Welch](https://medium.com/mlearning-ai/baum-welch-algorithm-4d4514cf9dbe)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88220bf2",
   "metadata": {},
   "source": [
    "pomegranate is extremely well featured when it comes to regularization methods for training, supporting tied emissions and edges, edge and emission inertia, freezing nodes or edges, edge pseudocounts, and multithreaded training. Lets look at some examples of the following:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
