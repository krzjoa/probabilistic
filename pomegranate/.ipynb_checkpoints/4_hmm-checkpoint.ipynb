{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67eb26b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn; seaborn.set_style('whitegrid')\n",
    "import numpy as np\n",
    "\n",
    "from pomegranate import *\n",
    "\n",
    "np.random.seed(0)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c17e5d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65210533",
   "metadata": {},
   "source": [
    "## CG rich region identification example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200b63a5",
   "metadata": {},
   "source": [
    "Lets take the simplified example of CG island detection on a sequence of DNA. DNA is made up of the four canonical nucleotides, abbreviated 'A', 'C', 'G', and 'T'. We can say that regions of the genome that are enriched for nucleotides 'C' and 'G' are 'CG islands', which is a simplification of the real biological concept but sufficient for our example. The issue with identifying these regions is that they are not exclusively made up of the nucleotides 'C' and 'G', but have some 'A's and 'T's scatted amongst them. A simple model that looked for long stretches of C's and G's would not perform well, because it would miss most of the real regions.\n",
    "\n",
    "We can start off by building the model. Because HMMs involve the transition matrix, which is often represented using a graph over the hidden states, building them requires a few more steps that a simple distribution or the mixture model. Our simple model will be composed of two distributions. One distribution wil be a uniform distribution across all four characters and one will have a preference for the nucleotides C and G, while still allowing the nucleotides A and T to be present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74b0af64",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = DiscreteDistribution({'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25})\n",
    "d2 = DiscreteDistribution({'A': 0.10, 'C': 0.40, 'G': 0.40, 'T': 0.10}) # << C i G występują tutaj częściej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f70079ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiujemy dwa stany\n",
    "s1 = State(d1, name='background')\n",
    "s2 = State(d2, name='CG island')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f70088ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzymy model HMM\n",
    "model = HiddenMarkovModel()\n",
    "model.add_states(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15fa9292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dodajemy prawdopodbieństwa przejścia ze stanu do stanu\n",
    "model.add_transition(model.start, s1, 0.5)\n",
    "model.add_transition(model.start, s2, 0.5)\n",
    "model.add_transition(s1, s1, 0.9)\n",
    "model.add_transition(s1, s2, 0.1)\n",
    "model.add_transition(s2, s1, 0.1)\n",
    "model.add_transition(s2, s2, 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06e20af",
   "metadata": {},
   "source": [
    "Now, finally, we need to bake the model in order to finalize the internal structure. Bake must be called when the model has been fully specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a948722",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.bake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d56a1df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence: CGACTACTGACTACTCGCCGACGCGACTGCCGTCTATACTGCGCATACGGC\n",
      "hmm pred: 111111111111111000000000000000011111111111111110000\n"
     ]
    }
   ],
   "source": [
    "# Uwaga! Indeksy nie odziweciedlają kolejności dodawania stanów\n",
    "seq = numpy.array(list('CGACTACTGACTACTCGCCGACGCGACTGCCGTCTATACTGCGCATACGGC'))\n",
    "\n",
    "hmm_predictions = model.predict(seq)\n",
    "\n",
    "print(\"sequence: {}\".format(''.join(seq)))\n",
    "print(\"hmm pred: {}\".format(''.join(map( str, hmm_predictions))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367f3206",
   "metadata": {},
   "source": [
    "> The predicted integers don't correspond to the order in which states were added to the model, but rather, the order that they exist in the model after a topological sort. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88601771",
   "metadata": {},
   "source": [
    "Let's say, though, that we want to get rid of that CG island prediction at the end because we don't believe that real islands can occur at the end of the sequence. We can take care of this by adding in an explicit end state that only the non-island hidden state can get to. We enforce that the model has to end in the end state, and if only the non-island state gets there, the sequence of hidden states must end in the non-island state. Here's how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f4f0fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HiddenMarkovModel()\n",
    "model.add_states(s1, s2)\n",
    "model.add_transition(model.start, s1, 0.5)\n",
    "model.add_transition(model.start, s2, 0.5)\n",
    "model.add_transition(s1, s1, 0.89 )\n",
    "model.add_transition(s1, s2, 0.10 )\n",
    "model.add_transition(s1, model.end, 0.01)\n",
    "model.add_transition(s2, s1, 0.1)\n",
    "model.add_transition(s2, s2, 0.9)\n",
    "model.bake()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba18db9d",
   "metadata": {},
   "source": [
    "Note that all we did was add a transition from s1 to model.end with some low probability. This probability doesn't have to be high if there's only a single transition there, because there's no other possible way of getting to the end state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8e8cc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence: CGACTACTGACTACTCGCCGACGCGACTGCCGTCTATACTGCGCATACGGC\n",
      "hmm pred: 111111111111111000000000000000011111111111111111111\n"
     ]
    }
   ],
   "source": [
    "seq = numpy.array(list('CGACTACTGACTACTCGCCGACGCGACTGCCGTCTATACTGCGCATACGGC'))\n",
    "\n",
    "hmm_predictions = model.predict(seq)\n",
    "\n",
    "print(\"sequence: {}\".format(''.join(seq)))\n",
    "print(\"hmm pred: {}\".format(''.join(map( str, hmm_predictions))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffaf234",
   "metadata": {},
   "source": [
    "In the same way that mixtures could provide probabilistic estimates of class assignments rather than only hard labels, hidden Markov models can do the same. These estimates are the posterior probabilities of belonging to each of the hidden states given the observation, but also given the rest of the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83a48c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.19841088 0.80158912]\n",
      " [0.32919701 0.67080299]\n",
      " [0.38366073 0.61633927]\n",
      " [0.58044619 0.41955381]\n",
      " [0.69075524 0.30924476]\n",
      " [0.74653183 0.25346817]\n",
      " [0.76392808 0.23607192]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict_proba(seq)[12:19])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63594314",
   "metadata": {},
   "source": [
    "Oprócz wyliczenia powyższych prawdopodobieństw (posterior probability), możemy również sprawdzić przewidywaną liczbę przejść między stanami ukrytymi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa98b399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15.78100555  2.89559314  0.          0.        ]\n",
      " [ 2.41288774 28.91051356  0.          1.        ]\n",
      " [ 0.4827054   0.5172946   0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "trans, ems = model.forward_backward(seq)\n",
    "print(trans)\n",
    "# ems = emission (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5cf3bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{\n",
       "     \"class\" : \"State\",\n",
       "     \"distribution\" : {\n",
       "         \"class\" : \"Distribution\",\n",
       "         \"dtype\" : \"str\",\n",
       "         \"name\" : \"DiscreteDistribution\",\n",
       "         \"parameters\" : [\n",
       "             {\n",
       "                 \"A\" : 0.1,\n",
       "                 \"C\" : 0.4,\n",
       "                 \"G\" : 0.4,\n",
       "                 \"T\" : 0.1\n",
       "             }\n",
       "         ],\n",
       "         \"frozen\" : false\n",
       "     },\n",
       "     \"name\" : \"CG island\",\n",
       "     \"weight\" : 1.0\n",
       " },\n",
       " {\n",
       "     \"class\" : \"State\",\n",
       "     \"distribution\" : {\n",
       "         \"class\" : \"Distribution\",\n",
       "         \"dtype\" : \"str\",\n",
       "         \"name\" : \"DiscreteDistribution\",\n",
       "         \"parameters\" : [\n",
       "             {\n",
       "                 \"A\" : 0.25,\n",
       "                 \"C\" : 0.25,\n",
       "                 \"G\" : 0.25,\n",
       "                 \"T\" : 0.25\n",
       "             }\n",
       "         ],\n",
       "         \"frozen\" : false\n",
       "     },\n",
       "     \"name\" : \"background\",\n",
       "     \"weight\" : 1.0\n",
       " },\n",
       " {\n",
       "     \"class\" : \"State\",\n",
       "     \"distribution\" : null,\n",
       "     \"name\" : \"None-start\",\n",
       "     \"weight\" : 1.0\n",
       " },\n",
       " {\n",
       "     \"class\" : \"State\",\n",
       "     \"distribution\" : null,\n",
       "     \"name\" : \"None-end\",\n",
       "     \"weight\" : 1.0\n",
       " }]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kolejność stanów - wiersze macierzy powyżej:\n",
    "# * CG island\n",
    "# * background\n",
    "# * start\n",
    "# * end\n",
    "# \n",
    "# Ze stanu końowego nie przejdziemy już nigdzie, \n",
    "# Nieco częściej przechodzimy ze stanu CG do stanu background, najczęciej pozostajemy w obrębie tego samego stanu.\n",
    "model.states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e049a8",
   "metadata": {},
   "source": [
    "This is the transition table, which has the **soft count** of the number of transitions across an edge in the model given a single sequence. It is a square matrix of size equal to the number of states (including start and end state), with number of transitions from (row_id) to (column_id). This is exemplified by the 1.0 in the first row, indicating that there is one transition from background state to the end state, as that's the only way to reach the end state. However, the third (or fourth, depending on ordering) row is the transitions from the start state, and it only slightly favors the background state. These counts are not normalized to the length of the input sequence, but can easily be done so by dividing by row sums, column sums, or entire table sums, depending on your application.\n",
    "\n",
    "A possible reason not to normalize is to run several sequences through and add up their tables, because normalizing in the end and extracting some domain knowledge. It is extremely useful in practice. For example, we can see that there is an expectation of ~2.9 transitions from CG island to background, and ~2.4 from background to CG island. This could be used to infer that there are ~2-3 edges, which makes sense if you consider that the start and end of the sequence seem like they might be part of the CG island states except for the strict transition probabilities used (look at the first few rows of the emission table above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9369a773",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
